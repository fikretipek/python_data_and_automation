import whisper
import ffmpeg
import os
import numpy as np
import soundfile as sf

# ---- AYARLAR ----
video_path = r"C:\Test\output.mp4"
audio_path = r"C:\Test\temp_audio.wav"
srt_path = r"C:\Test\output.srt"
language = "en"
model_size = "base"
ffmpeg_exe = r"C:\ffmpeg\bin\ffmpeg.exe"  # kendi sisteminize gÃ¶re

# 1ï¸âƒ£ Videodan WAV Ã§Ä±kar
print("ğŸ”¹ Videodan ses Ã§Ä±karÄ±lÄ±yor...")
(
    ffmpeg
    .input(video_path)
    .output(audio_path, ar=16000, ac=1)
    .run(cmd=ffmpeg_exe, overwrite_output=True, quiet=True)
)

# 2ï¸âƒ£ Whisper modelini yÃ¼kle
print(f"ğŸ”¹ Whisper '{model_size}' modeli yÃ¼kleniyor...")
model = whisper.load_model(model_size)

# 3ï¸âƒ£ WAV dosyasÄ±nÄ± yÃ¼kle
print("ğŸ”¹ WAV dosyasÄ± numpy array olarak yÃ¼kleniyor...")
audio, sr = sf.read(audio_path)
if len(audio.shape) > 1:
    audio = np.mean(audio, axis=1)  # stereo ise mono yap
audio = audio.astype(np.float32)    # âš¡ float32 yap

# 4ï¸âƒ£ Transkription
print("ğŸ”¹ AltyazÄ± oluÅŸturuluyor...")
result = model.transcribe(audio, language=language, fp16=False)

# 5ï¸âƒ£ SRT formatÄ±na Ã§evir ve kaydet
print("ğŸ”¹ SRT dosyasÄ± oluÅŸturuluyor...")
def format_timestamp(seconds):
    h = int(seconds // 3600)
    m = int((seconds % 3600) // 60)
    s = int(seconds % 60)
    ms = int((seconds - int(seconds)) * 1000)
    return f"{h:02}:{m:02}:{s:02},{ms:03}"

with open(srt_path, "w", encoding="utf-8") as f:
    for i, seg in enumerate(result["segments"], 1):
        start = format_timestamp(seg["start"])
        end = format_timestamp(seg["end"])
        text = seg["text"].strip()
        f.write(f"{i}\n{start} --> {end}\n{text}\n\n")

print(f"âœ… AltyazÄ± oluÅŸturuldu: {srt_path}")

# 6ï¸âƒ£ GeÃ§ici audio dosyasÄ±nÄ± sil
os.remove(audio_path)
print("ğŸ—‘ï¸ GeÃ§ici dosya silindi.")
